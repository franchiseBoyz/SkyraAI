{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe4a67b6-9cc2-428e-a6f3-46a2dc40334c",
   "metadata": {
    "microsoft": {
     "language": "python",
     "language_group": "synapse_pyspark"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.livy.statement-meta+json": {
       "execution_finish_time": "2025-04-09T01:03:37.3203189Z",
       "execution_start_time": "2025-04-09T01:03:21.0462665Z",
       "livy_statement_state": "available",
       "normalized_state": "finished",
       "parent_msg_id": "9ade9e1a-7f35-428c-8e22-32521afd70c4",
       "queued_time": "2025-04-09T01:03:21.0450873Z",
       "session_id": "9f7e89ac-07c2-4283-ad48-2c252bc7b330",
       "session_start_time": null,
       "spark_pool": null,
       "state": "finished",
       "statement_id": 7,
       "statement_ids": [
        7
       ]
      },
      "text/plain": [
       "StatementMeta(, 9f7e89ac-07c2-4283-ad48-2c252bc7b330, 7, Finished, Available, Finished)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Databricks notebook source\n",
    "from datetime import datetime\n",
    "\n",
    "def log_pipeline_event(status, message):\n",
    "    spark.sql(f\"\"\"\n",
    "    INSERT INTO pipeline_quality_checks VALUES (\n",
    "        current_timestamp(),\n",
    "        'pipeline_run',\n",
    "        '{status}',\n",
    "        NULL,\n",
    "        '{message}'\n",
    "    )\n",
    "    \"\"\")\n",
    "\n",
    "try:\n",
    "    # 1. Log start\n",
    "    log_pipeline_event(\"STARTED\", f\"Pipeline started at {datetime.now()}\")\n",
    "    # 2. Run the ETL pipeline\n",
    "\n",
    "    # 2.1. Read data from bronze layer\n",
    "    bronze_df = spark.sql(\"SELECT * FROM bronze_stock_data\")\n",
    "    # 2.2. Process data\n",
    "    processed_df = bronze_df.withColumn(\"processed_date\", current_timestamp())\n",
    "    # 2.3. Write data to silver layer\n",
    "    processed_df.write.mode(\"overwrite\").saveAsTable(\"silver_stock_data\")\n",
    "    # 2.4. Run quality checks\n",
    "    quality_check_df = spark.sql(\"\"\"\n",
    "        SELECT COUNT(*) AS record_count FROM silver_stock_data\n",
    "        WHERE stock_price IS NOT NULL\n",
    "    \"\"\")\n",
    "    # 2.5. Write data to gold layer\n",
    "    quality_check_df.write.mode(\"overwrite\").saveAsTable(\"gold_stock_analysis\")\n",
    "    # 3. Log completion\n",
    "    log_pipeline_event(\"COMPLETED\", f\"Pipeline completed at {datetime.now()}\")\n",
    "    # 4. Log record count\n",
    "    # 4.1. Count records in gold layer\n",
    "    # 4.2. Log record count\n",
    "    # 4.3. Log completion\n",
    "    record_count = spark.sql(\"SELECT COUNT(*) FROM gold_stock_analysis\").collect()[0][0]\n",
    "    log_pipeline_event(\"COMPLETED\", f\"Processed {record_count} records at {datetime.now()}\")\n",
    "    \n",
    "except Exception as e:\n",
    "    log_pipeline_event(\"FAILED\", f\"Error: {str(e)}\")\n",
    "    raise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f66f9151-251e-473f-b127-c51826c0b047",
   "metadata": {
    "microsoft": {
     "language": "python",
     "language_group": "synapse_pyspark"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01da19fe-ab8a-4e57-8807-27a95e0d4f91",
   "metadata": {
    "microsoft": {
     "language": "python",
     "language_group": "synapse_pyspark"
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "dependencies": {
   "lakehouse": {
    "default_lakehouse": "9fcf25e4-bcf6-4847-a2c5-ec74b917eba3",
    "default_lakehouse_name": "FinanceAI_LakeHouse",
    "default_lakehouse_workspace_id": "372f23e9-33a7-4bfc-9af5-24bc9d55336a",
    "known_lakehouses": [
     {
      "id": "9fcf25e4-bcf6-4847-a2c5-ec74b917eba3"
     }
    ]
   }
  },
  "kernel_info": {
   "name": "synapse_pyspark"
  },
  "kernelspec": {
   "display_name": "Synapse PySpark",
   "language": "Python",
   "name": "synapse_pyspark"
  },
  "language_info": {
   "name": "python"
  },
  "microsoft": {
   "language": "python",
   "language_group": "synapse_pyspark",
   "ms_spell_check": {
    "ms_spell_check_language": "en"
   }
  },
  "nteract": {
   "version": "nteract-front-end@1.0.0"
  },
  "spark_compute": {
   "compute_id": "/trident/default",
   "session_options": {
    "conf": {
     "spark.synapse.nbs.session.timeout": "1200000"
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
